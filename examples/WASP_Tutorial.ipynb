{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2385d319",
   "metadata": {},
   "source": [
    "# Wavelet and simulated Annealing SliP (WASP) Tutorial\n",
    "***\n",
    "***\n",
    "The Wavelet and simulated Annealing SliP (WASP) code is for finite fault inversions (slip inversions) using a non-linear inversion method in the wavelet domain to model slip amplitude, rake, rupture time, and rise time on a discretized fault plane (Ji et al., 2002). To solve the non-linear problem, WASP uses the heat-bath simulated annealing inverse method. WASP has been developed by Pablo Koch (University of Chile, Santiago) with Python wrappers to the underlying Fortran scripts (Ji et al., 2002; Koch et al., 2019; Goldberg et al., 2022).\n",
    "\n",
    "WASP has been tested on Linux machomes and on a PC using Windows Subsystem for Linux.\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/SlipDistribution_example.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "### Users of this code should consider citing the following relevant publications:\n",
    "- Goldberg, D. E., P. Koch, D. Melgar, S. Riquelme, and W. L. Yeck (2022). Beyond the Teleseism: Introducing Regional Seismic and Geodetic Data into Routine USGS Finite Fault Modeling, Seismological Research Letters, 93, 3308–3323, https://doi.org/10.1785/0220220047.\n",
    "- Ji, C., D. J. Wald, and D. V. Helmberger (2002). Source description of the 1999 Hector Mine, California, earthquake, Part I: Wavelet domain inversion theory and resolution analysis, Bulletin of the Seismological Society of America, 92, no. 4, 1192–1207, https://doi.org/10.1785/0120000916.\n",
    "- Koch, P., F. Bravo, S. Riquelme, and J. G. F. Crempien (2019). Near-real-time finite-fault inversions for large earthquakes in Chile using strong-motion data, Seismological Research Letters, 90, no. 5, 1971–1986, https://doi.org/10.1785/0220180294.\n",
    "- Zhu, L., & Rivera, L. A. (2002). A note on the dynamic and static displacements from a point source in multilayered media: A note on the dynamic and static displacements from a point source. Geophysical Journal International, 148(3), 619–627. https://doi.org/10.1046/j.1365-246X.2002.01610.x.\n",
    "***\n",
    "\n",
    "\n",
    "### To run a slip inversion, all you need is:\n",
    "1. a moment tensor (in CMTSOLUTION format), and\n",
    "2. at least one of the following data types  \n",
    "    a. broadband teleseismic waveforms,  \n",
    "    b. local strong-motion accelerometer waveforms,  \n",
    "    c. local high-rate Global Navigation Satellite Systems (GNSS) displacement waveforms,  \n",
    "    d. static GNSS offsets, and/ or  \n",
    "    e. downsampled InSAR interferograms.\n",
    "    \n",
    "Waveforms must be in SAC format, and have station name, channel, longitude, and latitude in the header. Static data must be in text files, formatted like the example data (see https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316).\n",
    "***\n",
    "\n",
    "### This notebook walks through a slip inversion of the 2015 Mw8.3 Illapel, Chile, earthquake.\n",
    "\n",
    "This tutorial will go through:\n",
    "\n",
    "0. [Software Installation](#install)  \n",
    "1. [Running an initial automated inversion](#auto)\n",
    "2. [Checking the results and making modifications:](#iterate)  \n",
    "    2.1. [Managing jsons and updating parameters in text files: input_files.py](#input_files)  \n",
    "    2.2. [The stations included (and their weights): modify_jsons.py](#modify_jsons)  \n",
    "    2.3. [The fault orientation: modify segments_data.json](#segments_data)  \n",
    "    2.4. [Timing of arrivals: shift_match.py](#shift_match)  \n",
    "    2.5. [Modifying the crustal velocity model](#velmod)\n",
    "3. [Adding data types: -o add_data](#add_data)  \n",
    "    3.1. [strong-motion accelerometer](#strong)  \n",
    "    3.2. [high-rate Global Navigation Satellite Systems (GNSS)](#cgps)  \n",
    "    3.3. [static GNSS](#gps)  \n",
    "    3.4. [InSAR line of sight displacements](#insar)\n",
    "4. [Multi-segment models](#multi_segment)\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f974f6",
   "metadata": {},
   "source": [
    "# <a id='install'></a> 0. Installation\n",
    "The WASP code is housed in a USGS GitLab repository: https://code.usgs.gov/ghsc/neic/algorithms/neic-finitefault.  \n",
    "Installation instructions are avialable in the README file at that link: https://code.usgs.gov/ghsc/neic/algorithms/neic-finitefault/-/blob/main/README.md\n",
    "\n",
    "### Download Tutorial Data \n",
    "Necessary data for this tutorial is available in a USGS ScienceBase Data Release: https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316\n",
    "We will download, unzip, and save the following files in the same directory as this tutorial:  \n",
    "\n",
    "    a. 20003k7a_cmt_CMT  \n",
    "    b. Teleseismic_Data.zip  \n",
    "    c. StrongMotion_Accelerometer_Data.zip  \n",
    "    d. HighRateGNSS_Data.zip  \n",
    "    e. gps_data  \n",
    "    f. s1_20150824-20150917_p156_descending.txt  \n",
    "    g. s1_20150826-20150919_p18_ascending.txt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8285bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Data files to download from ScienceBase\n",
    "data_files = [\"Teleseismic_Data.zip\", \"StrongMotion_Accelerometer_Data.zip\", \"HighRateGNSS_Data.zip\", \"gps_data\", \\\n",
    "              \"s1_20150824-20150917_p156_descending.txt\", \"s1_20150826-20150919_p18_ascending.txt\", \"20003k7a_cmt_CMT\"]\n",
    "\n",
    "item_url = \"https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316?format=json\"\n",
    "response = requests.get(item_url)\n",
    "jdict = response.json()\n",
    "print(f'Downloading Data from ScienceBase Data Release: \\n {jdict[\"title\"]}: {jdict[\"subTitle\"]}')\n",
    "filenames = [f[\"name\"] for f in jdict[\"files\"]]\n",
    "for data_download in range(len(data_files)):\n",
    "    idx = filenames.index(data_files[data_download])\n",
    "    file_url = jdict[\"files\"][idx][\"downloadUri\"]\n",
    "    response2 = requests.get(file_url)\n",
    "    data = response2.content\n",
    "    filename = data_files[data_download]\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    if zipfile.is_zipfile(data_files[data_download]):\n",
    "        print(f'Unzipping Waveform Data: {data_files[data_download]}')\n",
    "        myzip = zipfile.ZipFile(data_files[data_download])\n",
    "        out_dir = data_files[data_download].split('.')[0]\n",
    "        myzip.extractall(out_dir)\n",
    "        pathlib.Path(data_files[data_download]).unlink()\n",
    "print('Creating Static_Data Directory')\n",
    "static_dir = pathlib.Path('Static_Data')\n",
    "if not static_dir.exists():\n",
    "    static_dir.mkdir()\n",
    "static_files = [\"gps_data\", \"s1_20150824-20150917_p156_descending.txt\", \"s1_20150826-20150919_p18_ascending.txt\"]\n",
    "for static in range(len(static_files)):\n",
    "    infile = pathlib.Path(static_files[static])\n",
    "    outfile = static_dir / static_files[static]\n",
    "    infile.rename(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e66a75",
   "metadata": {},
   "source": [
    "# <a id='auto'></a> 1. We'll start with an initial \"auto\" inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to your WASP installation and to the location of this tutorial:\n",
    "WASP_directory=\"/data/WASP\"\n",
    "WASP_tutorial=\"/data/degoldberg/FiniteFault/WASP_Tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaad9e2",
   "metadata": {},
   "source": [
    "Let's load and take a look at the example CMT file:  \n",
    "This is how WASP calculates the nodal planes on which to model slip and from where it pulls the hypocenter and centroid locations, as well as the target seismic moment.\n",
    "\n",
    "An explanation of the CMTSOLUTION format is available here: http://eost.u-strasbg.fr/wphase/wiki/doku.php/wphase:documentation#data_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b53ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"20003k7a_cmt_CMT\", \"r\")\n",
    "cmt_content = f.read()\n",
    "print(cmt_content)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad981c",
   "metadata": {},
   "source": [
    "The python call to run the automatic inversion can use any of the available data types:\n",
    "1. -t (teleseismic body waves)  \n",
    "2. -su (teleseismic surface waves)  \n",
    "3. -st (strong-motion accelerometer)  \n",
    "4. --cgps (continuous (high-rate) GPS/GNSS)  \n",
    "5. --gps (static GPS/GNSS)  \n",
    "6. -in (InSAR)\n",
    "\n",
    "<a id='tele'></a> In this initial run, we'll stick with teleseismic observations (-t -su).  \n",
    "This step will take a few minutes, and you'll see a lot of output to the screen describing the processing step. When the inversion starts, it will go through 250 iterations (iter) of simulated annealing for each of the two potential nodal planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {WASP_directory}/src/wasp/inversion_chen_new.py -o auto -gcmt 20003k7a_cmt_CMT -d Teleseismic_Data/Teleseismic_Data/ -t -su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798874a0",
   "metadata": {},
   "source": [
    "If this was successful, you'll have seen two different instances of the output reaching \"iter: 250\" and then a quick summary of run, including the text \"END CHEN-JI'S WAVELET KINEMATIC MODELLING METHOD.\"\n",
    "\n",
    "This will have created a new directory in your current working directory with the event origin time, YYYMMDDHHMNSS. For the Illapel example, the directory will be called 20150916225432. In that directory, you'll find another directory called ffm.0, meaning the first run of the finite-fault modeling (ffm) code. If you have run the script above more than once, subsequent runs will be in directories ffm.1, ffm.2, etc. Note that this applies even if there was an error running the script above. Feel free to delete failed runs, as not to end up with unnecessary ffm.X directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103899d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the event origin time YYYYMMDDHHMNSS and the ffm.X directory created by the script above (likely ffm.0)\n",
    "event_OT='20150916225432'\n",
    "ffm_run='ffm.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf115a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {event_OT}/{ffm_run}/\n",
    "# Check out the directories this initial inversion created:\n",
    "!ls -d */"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99e4e4",
   "metadata": {},
   "source": [
    "### Contents of the ffm.X directory\n",
    "1. ***data***: where all the raw and processed data is stored for future use  \n",
    "2. ***logs***: a history of what the inversion did  \n",
    "3. ***NP1***: inversion results on Nodal Plane 1  \n",
    "4. ***NP2***: inversion results on Nodal Plane 2  \n",
    "5. ***plots***: Figures associated with the automated run\n",
    "\n",
    "It is up to the user to determine which of the two nodal planes is the causative fault. In this case, we know that the Illapel event was on the subduction interface. Looking at the file segments_data.json within NP1 and NP2, you can find the orienation information to determine which nodal plane corresponds to the subduction interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e941c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat NP1/segments_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28464c8d",
   "metadata": {},
   "source": [
    "From the segments_data.json file in the Nodal Plane 1 (NP1) directory, we see it has a strike of 6.6, a dip of 19, and a rake of 109, consistent with the subduction interface. This is the NPx directory we want to work in. Updates can be made directly in the directory, or you can copy the directory to a new working directory in order to preserve the inversion history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see what that automated solution looks like by making some plots\n",
    "# Try out the help function first to see all the options\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee35b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only have teleseismic data in our inversion, so we want to plot the FFM solution (-ffms)\n",
    "# and the teleseismic waveform fits (-t and -su)\n",
    "# This step can take a couple minutes if you have a large map area\n",
    "%cd NP1\n",
    "!rm plots/*\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b837f",
   "metadata": {},
   "source": [
    "Go look in the NP1.0/plots directory to see what you've got:\n",
    "1. ***Love_surf_waves.png***: Love surface wave observations (black) and model fits (red)\n",
    "2. ***Map.png***: Map view of fault plane and inversion results\n",
    "3. ***MomentRate.png***: Moment rate function (aka source time function)\n",
    "4. ***P_body_waves.png***: P- body wave observations (black) and model fits (red)\n",
    "5. ***Rayleigh_surf_waves.png***: Rayleigh surface wave observations (black) and model fits (red)\n",
    "6. ***SH_body_waves.png***: SH- body wave observations (black) and model fits (red)\n",
    "7. ***SlipDist_plane0.png***: Slip distribution in along-strike and along-dip projection for zero-th fault segment.\n",
    "8. ***SlipTime_plane0.png***: Plots showing rupture onset time, rupture velocity and slip duration (rise time) for zero-th fault segment. Use these with caution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the Love wave fits.\n",
    "from IPython import display\n",
    "display.Image('plots/Love_surf_waves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ed966",
   "metadata": {},
   "source": [
    "Note that a few of these stations are wonky looking. For example, HOPE appears to be off in both amplitude and frequency, as are ASCN and CMLA. Keep these in mind. In the subsequent inversion, we can downweight poor stations to get a more reliable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f9a67",
   "metadata": {},
   "source": [
    "# <a id='iterate'></a> 2. Let's iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6afe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's update the solution for NP1 in a new directory called NP1.0 so we don't lose the auto inversion\n",
    "%cd ..\n",
    "!cp -r NP1 NP1.0\n",
    "!pwd\n",
    "# Head into your new directory\n",
    "%cd NP1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d53b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the .json files that allow you to make modifications to your next run\n",
    "!ls *json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9006510",
   "metadata": {},
   "source": [
    "## <a id='input_files'></a>Take a look at the .json files available in the directory.\n",
    "\n",
    "1. **annealing_prop.json:** Includes parameters for the simulated annealing, which you can adjust here.\n",
    "2. **model_space.json:** Describes how different fault segments connect (if applicable) and also limits max slip and slip at fault edges, if desired.\n",
    "3. **sampling_filter.json:** Describes the filter parameters used in data processing.\n",
    "4. **segments_data.json:** Fault segment information including strike, dip, rake, subfault sizes, hypocenter location on fault\n",
    "5. **surf_waves.json:** Surface waves (Rayleigh [BHZ] and Love [SH]) included in the inversion and their weights\n",
    "6. **tele_waves.json:** Teleseismic body waves (P (BHZ) and SH) included in the inversion and their weights\n",
    "7. **tensor_info.json:** JSON format of the CMT file used as input to the auto inversion. If you want to change hypocenter parameters in future iterations, this is the place.\n",
    "8. **velmodel_data.json:** 1D velocity structure pulled from LITH1.0 and used for the Green's function calculations. You can substitute a different local 1D structure, but you will have to recalculate all the Green's function banks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c999d",
   "metadata": {},
   "source": [
    "##  <a id='input_files'></a>2.1. Managing .json files and updating .txt files:\n",
    "Nearly all necessary inversion parameter modifications should be made within the .json files listed above. Modifications made to the .json files are propagated to the necessary .txt files using the python script \"input_files.py\". Whenever a modification is made to a .json file, run input_files.py with the appropriate flag to corresponding to the .json file you have modified. The most common are listed below:  \n",
    "1. **-t**: updates to the teleseismic body wave data (tele_waves.json)\n",
    "2. **-su**: updates to the teleseismic surface wave data (surf_waves.json)\n",
    "3. **-st**: updates to the strong motion accelerometer data (strong_motion_waves.json)*\n",
    "4. **--cgps**: updates to the high-rate GPS/GNSS data (cgps_waves.json)*\n",
    "5. **--gps**: updates to the static GPS/GNSS data (static_data.json)*\n",
    "6. **-in**: updates to the insar data (insar_data.json)*\n",
    "7. **-p**: updates to the fault plane orientation (segments_data.json) or velocity model (velmodel_data.json)\n",
    "8. **-a**: updates to the annealing parameters (annealing_prop.json)\n",
    "9. **-m**: updates to the model space parameters (model_space.json)  \n",
    "\n",
    "*These .jsons won't exist until we add those data to the inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348c48e",
   "metadata": {},
   "source": [
    "## <a id='modify_jsons'></a>2.2. Remove/ downweight poor stations\n",
    "\n",
    "We'll use the python script modify_jsons.py, which will change the weights of stations in the surf_waves.json or tele_waves.json to zero (using the \"downweight\" flag -dn) or remove the station entirely (using the \"delete\" flag -del). Open the waveform fit plots to decide which stations you want to downweight or remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d340c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run the help command, -h, to see the options\n",
    "!python {WASP_directory}/src/wasp/modify_jsons.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291c51b",
   "metadata": {},
   "source": [
    "Note that station HOPE is super wonky looking in both surface waves (Love and Rayleigh).\n",
    "We will address this by downweighting the station to zero weight using the script modify_jsons.py. We could delete the channel completely, but sometimes modifying other parameters allows stations that look wonky in the automated inversion to fit better later. Downweighting to zero allows you to keep seeing the station fit, so you can upweight it again later if desired.\n",
    "\n",
    "When using this command outside of the Jupyter notebook, you can run it as \"python .../modify_jsons.py -dn -su\" to downweight teleseismic body waves to zero. However, the interactive portion of the script doesn't work that way in a Jupyter notebook. Instead, we'll run the function directly, and feed it the surface_waves.json as the file that we want to modify, and assign the method to \"downweight\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e14b3-2dbe-4a65-8839-a38a19df7af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {WASP_directory}/src/wasp\n",
    "from modify_jsons import modify_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a98336-ff0b-4751-814e-9963ad469f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-weight poor surface wave channels to zero.\n",
    "# Note: BHZ component is Rayleigh Waves, SH is Love Waves\n",
    "modify_channels(f'{WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0/surf_waves.json',method='downweight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down-weight poor teleseismic body wave channels to zero.\n",
    "# Note: BHZ component is Rayleigh Waves, SH is Love Waves\n",
    "modify_channels(f'{WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0/tele_waves.json',method='downweight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be82247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit these changes by letting the .json files you just modified update their respective text files\n",
    "%cd {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0\n",
    "!python {WASP_directory}/src/wasp/input_files.py -t -su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09566db",
   "metadata": {},
   "source": [
    "## <a id='segments_data'></a> 2.3. Modify the fault orientation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa09636",
   "metadata": {},
   "source": [
    "By default, the planar fault is divided into ~225 subfaults. But these can end up being weird sizes. Open the segments_data.json file in your favorite editor and modify the delta_dip and delta_strike to be equal integers (i.e., square subfaults). If you make these values smaller, you may to add subfaults in the along-strike and along-dip directions (strike_subfaults and dip_subfaults, respectively) to make sure the fault area isn't too small, and you may want to move the hypocenter subfault location (hyp_stk, hyp_dip), to make sure the slip patch fits on the fault area.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Fault_Orientation.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 1.*** Description of segments_data.json parameters for fault orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ffe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take a look at the segments_data.json, to modify the fault orientation\n",
    "f = open('segments_data.json', 'r')\n",
    "fault_orientation = f.read()\n",
    "print(fault_orientation)\n",
    "f.close()\n",
    "\n",
    "#Open the segments_data.json separately and change some of the parameters.\n",
    "# For example, make the subfaults 15 x 15 km squares (delta_strike, delta_dip),\n",
    "# Change the number of subfaults along-strike or along-dip (strike_subfaults, dip_subfaults),\n",
    "# Move the entire fault plane relative to the hypocenter location (hyp_stk, hyp_dip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af862eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you've updated the fault parameters, you have to confirm this \n",
    "# change by asking the new .json to overwrite its associated text file.\n",
    "!python {WASP_directory}/src/wasp/input_files.py -p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c9013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you've changed the fault parameterization (and/or the waveforms being used), you also have to recalculate the Green's functions:\n",
    "!python {WASP_directory}/src/wasp/green_functions.py -t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfafdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, re-run the inversion:\n",
    "!{WASP_directory}/fortran_code/bin_inversion_gfortran_f95/run_modelling body surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot these results!\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb0132",
   "metadata": {},
   "source": [
    "Hey that's looking better! \n",
    "\n",
    "\n",
    "## <a id='shift_match'></a>2.4. Time shift\n",
    "\n",
    "Another simple thing we can do to improve the model is to shift the teleseismic waves in time. The calculated P- and S-wave arrival times might not be perfect (i.e., the velocity model isn't perfect), so we run a simple autocorrelation to align the observations and synthetics better in time. Use the python script shift_match.py in either 'match' or 'manual' mode. 'match' will use the autocorrelation, while 'manual' will allow you to shift it by the number of time steps you prefer. Using the \"-p\" flag will create a series of plots like Figure 2 to show how the waveforms have been shifted.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/FDF_SH_shiftmatch.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 2.*** Example of result of shift_match.py for SH-wave at station FDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58d49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First up, teleseismic body waves (-t tele)\n",
    "!python {WASP_directory}/src/wasp/shift_match.py -o match -t tele\n",
    "# Next up, surface waves (-t surf)\n",
    "!python {WASP_directory}/src/wasp/shift_match.py -o match -t surf\n",
    "# Since you've modified the waveform json files, don't forget to make it official:\n",
    "!python {WASP_directory}/src/wasp/input_files.py -t -su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alright, let's run that inversion one more time and plot the results\n",
    "!{WASP_directory}/fortran_code/bin_inversion_gfortran_f95/run_modelling body surf\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f71712",
   "metadata": {},
   "source": [
    "### Now you can repeat any of the steps above to modify the fault plane orientation in segments_data.json, remove or down-weight waveforms, shift waveforms in time to align better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9ed47",
   "metadata": {},
   "source": [
    "## 2.5.  <a id='velmod'></a> Modify crustal velocity model\n",
    "\n",
    "WASP automatically selects a 1D crustal velocity model from the centroid location using LITHO1.0 (https://doi.org/10.1002/2013JB010626). If you have a more specific local velocity model, you can substitute it. It's best to substitute **before** adding local data, to avoid having to recalculate local Green's functions, which can take a while.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Chile_crustal_velocity_model.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 3.*** 1D crustal velocity model for Northern Chile, from LITHO1.0\n",
    "\n",
    "To modify the local velocity model, open the velmodel_data.json file and input a value for each layer in the velocity model. Run \"python input_files.py -p\" to commit the changes in velmodel_data.json to the corresponding text file, vel_model.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bf4c7",
   "metadata": {},
   "source": [
    "# <a id='add_data'></a>3. And next, we can add local data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deced83",
   "metadata": {},
   "source": [
    "## <a id='strong'></a>Add  strong motion data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the strong motion accelerometer data (Strong_Motion_Data) to the inversion directory folder:\n",
    "%cp ../../../StrongMotion_Accelerometer_Data/* ../data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder to work in so you don't lose your history:\n",
    "%cd ..\n",
    "!cp -r NP1.0 NP1.1\n",
    "%cd NP1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"add_data\" function on inversion_chen_new.py (-o add_data)\n",
    "# Give it the path to the data directory where you just copied the data (-d ../data/)\n",
    "# Tell it you want it to add the strong motion data (-st)\n",
    "# FYI this will take a while, because it also needs to calculate local Green's functions!\n",
    "!python {WASP_directory}/src/wasp/inversion_chen_new.py -o add_data -d ../data/ -st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it! Don't forget to add the -st flag to plot the strong motion waveform fits\n",
    "#If you want to have station ID labels on the map, you can also include the -labels flag\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su -st -label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1214f",
   "metadata": {},
   "source": [
    "## <a id='cgps'></a> Now let's add the high-rate GNSS data, same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder to work in so you don't lose your history:\n",
    "%cd ..\n",
    "!cp -r NP1.1 NP1.2\n",
    "%cd NP1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47647c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the continous GPS data (HR_GNSS_Data) to the inversion directory folder:\n",
    "%cp ../../../HighRateGNSS_Data/* ../data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d364d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"add_data\" function on inversion_chen_new.py (-o add_data)\n",
    "# Give it the path to the data directory where you just copied the data (-d ../data/)\n",
    "# Tell it you want it to add the cGPS data (--cgps)\n",
    "# FYI this will take a while!\n",
    "!python {WASP_directory}/src/wasp/inversion_chen_new.py -o add_data -d ../data/ --cgps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80457bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot it up, and don't forget to add the --cgps flag!\n",
    "#If you want to have station ID labels on the map, you can also include the -labels flag\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su -st --cgps -label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a70dcf",
   "metadata": {},
   "source": [
    "## Now we have all the kinematic data included, let's move onto the static data\n",
    "### <a id='gps'></a>Starting with the static GNSS/GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "%cd ..\n",
    "!cp -r NP1.2 NP1.3\n",
    "%cd NP1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the gps_data text file into your working directory:\n",
    "!cp ../../../Static_Data/gps_data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da618d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gps_data file to create the necessary .json file:\n",
    "!python {WASP_directory}/src/wasp/data_management.py --gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use input_files.py to make the update to the json official:\n",
    "!python {WASP_directory}/src/wasp/input_files.py --gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to make Green's functions for the static station locations:\n",
    "# You can do this two ways: 1. The fortran script below, 2. The python wrapper \"greens_functions.py --gps\"\n",
    "# Here, let's do the fortran script so you can see the station output:\n",
    "!{WASP_directory}/fortran_code/src_dc_f95/gf_static_f95 gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a2cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the GFs for all the other datasets, which may have been deleted during cleanup\n",
    "!python {WASP_directory}/src/wasp/green_functions.py -t -st --cgps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb8bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alright, run a new inversion (and make plots) with all the available data so far!\n",
    "# Keep in mind that every time you add new data, the inversion will take a bit longer...\n",
    "!{WASP_directory}/fortran_code/bin_inversion_gfortran_f95/run_modelling body surf strong cgps gps\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su -st --cgps --gps -label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1abd6d",
   "metadata": {},
   "source": [
    "## Looking good! <a id='insar'></a>Time for InSAR data:\n",
    "### Prior to inclusion in WASP, InSAR observations must be processed to line-of-sight displacements, and down-sampled to some tractable number of observations (~1000 points per scene). Use the format in the example data files. Denote any header lines with '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e372673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "%cd ..\n",
    "!cp -r NP1.3 NP1.4\n",
    "%cd NP1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d251057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the downsampled InSAR data into the working directory\n",
    "!cp ../../../Static_Data/s1_20150824-20150917_p156_descending.txt .\n",
    "!cp ../../../Static_Data/s1_20150826-20150919_p18_ascending.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the necessary InSAR json files:\n",
    "# For organization (it doesn't matter for the inversion), mark the ascending file as -ina\n",
    "# Mark the descending file as -ind\n",
    "# WASP can allow for linear, bilinear, and quadratic \"ramps\" for each scene\n",
    "# Ramps are are specified in the flags -inar and -indr.\n",
    "# Here, we'll use the simplest version, linear ramps, for both.\n",
    "!python {WASP_directory}/src/wasp/data_management.py -in -ina s1_20150826-20150919_p18_ascending.txt -inar linear -ind s1_20150824-20150917_p156_descending.txt -indr linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348647e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use input_files.py to make those jsons official\n",
    "!python {WASP_directory}/src/wasp/input_files.py -in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcluate Green's functions.\n",
    "# Since these have a lot of datapoints, we'll use the python wrapper to avoid tons of output to screen\n",
    "# With a lot of data points, this could take a few minutes\n",
    "!python {WASP_directory}/src/wasp/green_functions.py -in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the inversion with all the data!\n",
    "!{WASP_directory}/fortran_code/bin_inversion_gfortran_f95/run_modelling body surf strong cgps gps insar\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su -st --cgps --gps -in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259d94d",
   "metadata": {},
   "source": [
    "### And there you have it, a finite fault model that includes many different instrument types.\n",
    "To finalize the inversion, go back and modify the fault orientation, subfault size, shift waveforms in time to match synthetics to observations better, remove bad stations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22657490",
   "metadata": {},
   "source": [
    "# <a id='multi_segment'></a> 4. Multi-segment models\n",
    "At present, WASP requires that slip be solved for on planar faults. However, we are not limited to one fault segment. WASP can model on 2+ planar segments, either connected at fault edges or completely independent. The 2015 Illapel earthquake ruptured only one fault (the megathrust), however, we can do a better job mimicking the increasing dip of the subduction zone with depth by changing our model from one plane with constant dip to two planes, with the deeper plane having slightly steeper dip.\n",
    "\n",
    "To include more than one planar fault segment, you must adjust two files:  \n",
    "1. segments_data.json  \n",
    "* Use hyp_stk and hyp_dip to locate the fault, relative to the location of the hypocenter\n",
    "* Use the “connections” field to describe how multiple planes are connected, in order to facilitate smoothing across the faults.\n",
    "2. model_space.json\n",
    "* Specify any constraints on slip amplitudes and allowable rakes\n",
    "* Specify whether plane is connected to any other planes in the up- or down-dip directions, or to the left or right (i.e., in the negative or positive along-strike directions)\n",
    "\n",
    "Examples of how you might modify these two files are in the Multisegment_Example folder.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Multi_Segment_Positions.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 4.*** Example of determining \"hyp_stk\" and \"hyp_dip\" for multi-segment models connected along-strike (segment 2) or along-dip (segment (3).\n",
    "\n",
    "In our case, the bottom of the shallow plane is connected to the top of the deeper plane. However, segments need not be connected at all- this is how you might model two events in close spatiotemporal proximity at once (e.g., Yeck et al., 2023). \n",
    "\n",
    "* Yeck, W.L. et al. Dense geophysical observations reveal a triggered, concurrent multi-fault rupture at the Mendocino Triple Junction. Commun Earth Environ 4, 94 (2023). https://doi.org/10.1038/s43247-023-00752-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50128cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "%cd ..\n",
    "!cp -r NP1.4 NP1.5\n",
    "%cd NP1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77275b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the example segments_data.json and model_space.json from the Multisegment_Example directory:\n",
    "!cp ../../../Multisegment_Example/segments_data.json .\n",
    "!cp ../../../Multisegment_Example/model_space.json .\n",
    "# Run input_files.py to update the text files:\n",
    "!python {WASP_directory}/src/wasp/input_files.py -p -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Green's functions for new configuration\n",
    "!python {WASP_directory}/src/wasp/green_functions.py -t -st --cgps --gps -in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80eb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the inversion with all the data!\n",
    "!{WASP_directory}/fortran_code/bin_inversion_gfortran_f95/run_modelling body surf strong cgps gps insar\n",
    "!python {WASP_directory}/src/wasp/plot_graphic_NEIC.py -ffms -t -su -st --cgps --gps -in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c2cbd",
   "metadata": {},
   "source": [
    "In these results, you will see some subtle changes. First, you now have 2 SlipDist plots, one for each plane. Also, when you open the Map plot, you'll see the two segments are separated, and there are now two red up-dip edges, one for each plane. This is fairly simplistic version of a multi-segment model, but users are encouraged to make their own more complex multi-segment models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32361097",
   "metadata": {},
   "source": [
    "### Congrats! You are ready to explore WASP on your own and model earthquakes of interest to you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e3091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
