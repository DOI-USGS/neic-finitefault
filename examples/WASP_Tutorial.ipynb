{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2385d319",
   "metadata": {},
   "source": [
    "# Wavelet and simulated Annealing SliP (WASP) Tutorial\n",
    "***\n",
    "***\n",
    "The Wavelet and simulated Annealing SliP (WASP) code is for finite fault inversions (slip inversions) using a non-linear inversion method in the wavelet domain to model slip amplitude, rake, rupture time, and rise time on a discretized fault plane (Ji et al., 2002). To solve the non-linear problem, WASP uses the heat-bath simulated annealing inverse method. WASP has been developed by Pablo Koch (University of Chile, Santiago) with Python wrappers to the underlying Fortran scripts (Ji et al., 2002; Koch et al., 2019; Goldberg et al., 2022).\n",
    "\n",
    "WASP has been tested on Linux machines and on a PC using Windows Subsystem for Linux.  \n",
    "***  \n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/SlipDistribution_example.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "### Users of this code should consider citing the following relevant publications:\n",
    "- Goldberg, D. E., P. Koch, D. Melgar, S. Riquelme, and W. L. Yeck (2022). Beyond the Teleseism: Introducing Regional Seismic and Geodetic Data into Routine USGS Finite Fault Modeling, Seismological Research Letters, 93, 3308–3323, https://doi.org/10.1785/0220220047.\n",
    "- Ji, C., D. J. Wald, and D. V. Helmberger (2002). Source description of the 1999 Hector Mine, California, earthquake, Part I: Wavelet domain inversion theory and resolution analysis, Bulletin of the Seismological Society of America, 92, no. 4, 1192–1207, https://doi.org/10.1785/0120000916.\n",
    "- Koch, P., F. Bravo, S. Riquelme, and J. G. F. Crempien (2019). Near-real-time finite-fault inversions for large earthquakes in Chile using strong-motion data, Seismological Research Letters, 90, no. 5, 1971–1986, https://doi.org/10.1785/0220180294.\n",
    "- Zhu, L., & Rivera, L. A. (2002). A note on the dynamic and static displacements from a point source in multilayered media: A note on the dynamic and static displacements from a point source. Geophysical Journal International, 148(3), 619–627. https://doi.org/10.1046/j.1365-246X.2002.01610.x.\n",
    "***\n",
    "\n",
    "\n",
    "### To run a slip inversion, all you need is:\n",
    "1. a moment tensor (in CMTSOLUTION format), and\n",
    "2. at least one of the following data types  \n",
    "    a. broadband teleseismic waveforms,  \n",
    "    b. local strong-motion accelerometer waveforms,  \n",
    "    c. local high-rate Global Navigation Satellite Systems (GNSS) displacement waveforms,  \n",
    "    d. static GNSS offsets, and/ or  \n",
    "    e. downsampled InSAR interferograms.\n",
    "    \n",
    "Waveforms must be in SAC format, and have station name, channel, longitude, and latitude in the header. Static data must be in text files, formatted like the example data (see https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316).\n",
    "***\n",
    "\n",
    "### This notebook walks through a slip inversion of the 2015 Mw8.3 Illapel, Chile, earthquake.\n",
    "\n",
    "This tutorial will go through:\n",
    "\n",
    "1. [Software Installation](#install)  \n",
    "2. [Running an initial automated inversion: `wasp model run auto_model`](#auto)\n",
    "3. [Checking the results and making modifications:](#iterate)  \n",
    "    3.1. [Managing json files and updating parameters in text files: `wasp manage update-inputs`](#input_files)  \n",
    "    3.2. [The stations included (and their weights): `wasp manage modify-dicts`](#modify_jsons)  \n",
    "    3.3. [The fault orientation: modify segments_data.json](#segments_data)  \n",
    "    3.4. [Timing of arrivals: `wasp process shift-match`](#shift_match)  \n",
    "    3.5. [Modifying the crustal velocity model](#velmod)\n",
    "4. [Adding data types: `wasp model run manual_model_add_data`](#add_data)  \n",
    "    4.1. [strong-motion accelerometer](#strong)  \n",
    "    4.2. [high-rate Global Navigation Satellite Systems (GNSS)](#cgps)  \n",
    "    4.3. [static GNSS](#gps)  \n",
    "    4.4. [InSAR line of sight displacements](#insar)\n",
    "5. [Multi-segment models](#multi_segment)\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f974f6",
   "metadata": {},
   "source": [
    "# <a id='install'></a> 1. Installation\n",
    "The WASP code is housed in a USGS GitLab repository: https://code.usgs.gov/ghsc/neic/algorithms/neic-finitefault.  \n",
    "Installation instructions are avialable in the README file at that link: https://code.usgs.gov/ghsc/neic/algorithms/neic-finitefault/-/blob/main/README.md\n",
    "\n",
    "*After following the installation instructions, you must activate your environment prior to launching this jupyter notebook (e.g., `poetry shell`)*\n",
    "\n",
    "### <a id='config'></a> 1.1 Check that you have a configuration file\n",
    "If this is your first time using WASP, set up your configuration file: `!wasp manage write-config`\n",
    "See your configuration file with the command `!wasp manage show-config`  \n",
    "\n",
    "\n",
    "### 1.2 Download Tutorial Data \n",
    "Necessary data for this tutorial is available in a USGS ScienceBase Data Release: https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316\n",
    "We will download, unzip, and save the following files in the same directory as this tutorial:  \n",
    "\n",
    "    a. 20003k7a_cmt_CMT  \n",
    "    b. Teleseismic_Data.zip  \n",
    "    c. StrongMotion_Accelerometer_Data.zip  \n",
    "    d. HighRateGNSS_Data.zip  \n",
    "    e. gps_data  \n",
    "    f. s1_20150824-20150917_p156_descending.txt  \n",
    "    g. s1_20150826-20150919_p18_ascending.txt\n",
    "    \n",
    "You can dowonload and organize the data manually, or simply by running the cell below (recommended), which will automatically pull the data from ScienceBase and organize the files as needed for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8285bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# Data files to download from ScienceBase\n",
    "data_files = [\"Teleseismic_Data.zip\", \"StrongMotion_Accelerometer_Data.zip\", \"HighRateGNSS_Data.zip\", \"gps_data\", \\\n",
    "              \"s1_20150824-20150917_p156_descending.txt\", \"s1_20150826-20150919_p18_ascending.txt\", \"20003k7a_cmt_CMT\"]\n",
    "\n",
    "item_url = \"https://www.sciencebase.gov/catalog/item/62852a66d34e3bef0c9a6316?format=json\"\n",
    "response = requests.get(item_url)\n",
    "jdict = response.json()\n",
    "print(f'Downloading Data from ScienceBase Data Release: \\n {jdict[\"title\"]}: {jdict[\"subTitle\"]}')\n",
    "filenames = [f[\"name\"] for f in jdict[\"files\"]]\n",
    "for data_download in range(len(data_files)):\n",
    "    idx = filenames.index(data_files[data_download])\n",
    "    file_url = jdict[\"files\"][idx][\"downloadUri\"]\n",
    "    response2 = requests.get(file_url)\n",
    "    data = response2.content\n",
    "    filename = data_files[data_download]\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(data)\n",
    "    if zipfile.is_zipfile(data_files[data_download]):\n",
    "        print(f'Unzipping Waveform Data: {data_files[data_download]}')\n",
    "        myzip = zipfile.ZipFile(data_files[data_download])\n",
    "        out_dir = data_files[data_download].split('.')[0]\n",
    "        myzip.extractall(out_dir)\n",
    "        pathlib.Path(data_files[data_download]).unlink()\n",
    "print('Creating Static_Data Directory')\n",
    "static_dir = pathlib.Path('Static_Data')\n",
    "if not static_dir.exists():\n",
    "    static_dir.mkdir()\n",
    "static_files = [\"gps_data\", \"s1_20150824-20150917_p156_descending.txt\", \"s1_20150826-20150919_p18_ascending.txt\"]\n",
    "for static in range(len(static_files)):\n",
    "    infile = pathlib.Path(static_files[static])\n",
    "    outfile = static_dir / static_files[static]\n",
    "    infile.rename(outfile)\n",
    "print('DOWNLOAD COMPLETE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e66a75",
   "metadata": {},
   "source": [
    "# <a id='auto'></a> 2. We'll start with an initial \"auto\" inversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcfdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to your WASP installation:\n",
    "WASP_directory = str(input(\"Input path to WASP: \"))\n",
    "# Unless you've moved it, the WASP tutorials is in the WASP_directory under \"examples\"\n",
    "WASP_tutorial = WASP_directory + \"/examples\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604453d",
   "metadata": {},
   "source": [
    "Make sure your configuration file looks right. If not, see [configuration file instructions](#config)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a8a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasp manage show-config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaad9e2",
   "metadata": {},
   "source": [
    "Let's load and take a look at the example CMT file:  \n",
    "This is how WASP calculates the nodal planes on which to model slip and from where it pulls the hypocenter and centroid locations, as well as the target seismic moment.\n",
    "\n",
    "An explanation of the CMTSOLUTION format is available here: http://eost.u-strasbg.fr/wphase/wiki/doku.php/wphase:documentation#data_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b53ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(WASP_tutorial + \"/20003k7a_cmt_CMT\", \"r\") as cmt:\n",
    "    print(cmt.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abad981c",
   "metadata": {},
   "source": [
    "The python call to run the automatic inversion can use any of the available data types:\n",
    "1. `-t body` (teleseismic body waves)  \n",
    "2. `-t surf` (teleseismic surface waves)  \n",
    "3. `-t strong` (strong-motion accelerometer)  \n",
    "4. `-t cgps` (continuous (high-rate) GPS/GNSS)  \n",
    "5. `-t gps` (static GPS/GNSS)  \n",
    "6. `-t in` (InSAR)\n",
    "\n",
    "<a id='tele'></a> In this initial run, we'll stick with teleseismic observations (`-t body -t surf`).  \n",
    "This step will take a few minutes, and you'll see a lot of output to the screen describing the processing step. When the inversion starts, it will go through 250 iterations (iter) of simulated annealing for each of the two potential nodal planes. It will also make automated plots for those two nodal planes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7806a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasp model run {WASP_tutorial} auto_model -g 20003k7a_cmt_CMT -d Teleseismic_Data -t body -t surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798874a0",
   "metadata": {},
   "source": [
    "If this was successful, you'll have seen two different instances of the output reaching \"iter: 250\" and then a quick summary of run, including the text \"END CHEN-JI'S WAVELET KINEMATIC MODELLING METHOD.\"\n",
    "\n",
    "This will have created a new directory in your current working directory with the event origin time, YYYMMDDHHMNSS. For the Illapel example, the directory will be called 20150916225432. In that directory, you'll find another directory called ffm.0, meaning the first run of the finite-fault modeling (ffm) code. If you have run the script above more than once, subsequent runs will be in directories ffm.1, ffm.2, etc. Note that this applies even if there was an error running the script above. Feel free to delete failed runs, as not to end up with unnecessary ffm.X directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103899d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the event origin time YYYYMMDDHHMNSS and the ffm.X directory created by the script above (likely ffm.0)\n",
    "event_OT='20150916225432'\n",
    "ffm_run='ffm.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf115a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the directories this initial inversion created:\n",
    "!ls -d {WASP_tutorial}/{event_OT}/{ffm_run}/*/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e99e4e4",
   "metadata": {},
   "source": [
    "### Contents of the ffm.X directory\n",
    "1. ***data***: where all the raw and processed data is stored for future use  \n",
    "2. ***logs***: a history of what the inversion did  \n",
    "3. ***NP1***: inversion results on Nodal Plane 1  \n",
    "4. ***NP2***: inversion results on Nodal Plane 2  \n",
    "5. ***plots***: Figures associated with the automated run\n",
    "\n",
    "It is up to the user to determine which of the two nodal planes is the causative fault. In this case, we know that the Illapel event was on the subduction interface. Looking at the file segments_data.json within NP1 and NP2, you can find the orienation information to determine which nodal plane corresponds to the subduction interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191e941c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat {WASP_tutorial}/{event_OT}/{ffm_run}/NP1/segments_data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28464c8d",
   "metadata": {},
   "source": [
    "From the segments_data.json file in the Nodal Plane 1 (NP1) directory, we see it has a strike of 6.6, a dip of 19, and a rake of 109, consistent with the subduction interface. This is the NPx directory we want to work in. Updates can be made directly in the directory, or you can copy the directory to a new working directory in order to preserve the inversion history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b837f",
   "metadata": {},
   "source": [
    "Go look in the NP1/plots directory to see what you've got:\n",
    "1. ***Love_surf_waves.png***: Love surface wave observations (black) and model fits (red)\n",
    "2. ***Map.png***: Map view of fault plane and inversion results\n",
    "3. ***MomentRate.png***: Moment rate function (aka source time function)\n",
    "4. ***P_body_waves.png***: P- body wave observations (black) and model fits (red)\n",
    "5. ***Rayleigh_surf_waves.png***: Rayleigh surface wave observations (black) and model fits (red)\n",
    "6. ***SH_body_waves.png***: SH- body wave observations (black) and model fits (red)\n",
    "7. ***SlipDist_plane0.png***: Slip distribution in along-strike and along-dip projection for zero-th fault segment.\n",
    "8. ***SlipTime_plane0.png***: Plots showing rupture onset time, rupture velocity and slip duration (rise time) for zero-th fault segment. Use these with caution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8c1435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the Love wave fits.\n",
    "from IPython import display\n",
    "display.Image(f'{WASP_tutorial}/{event_OT}/{ffm_run}/NP1/plots/Love_surf_waves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524ed966",
   "metadata": {},
   "source": [
    "Note that a few of these stations are wonky looking. For example, HOPE appears to be off in both amplitude and frequency, as are ASCN and CMLA. Keep these in mind. In the subsequent inversion, we can downweight poor stations to get a more reliable solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413f9a67",
   "metadata": {},
   "source": [
    "# <a id='iterate'></a> 3. Let's iterate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6afe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's update the solution for NP1 in a new directory called NP1.0 so we don't lose the auto inversion\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d53b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the .json files that allow you to make modifications to your next iteration\n",
    "!ls {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0/*json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9006510",
   "metadata": {},
   "source": [
    "## <a id='input_files'></a>Take a look at the .json files available in the directory.\n",
    "\n",
    "1. **annealing_prop.json:** Includes parameters for the simulated annealing, which you can adjust here.\n",
    "2. **model_space.json:** Describes how different fault segments connect (if applicable) and also limits max slip and slip at fault edges, if desired.\n",
    "3. **sampling_filter.json:** Describes the filter parameters used in data processing.\n",
    "4. **segments_data.json:** Fault segment information including strike, dip, rake, subfault sizes, hypocenter location on fault\n",
    "5. **surf_waves.json:** Surface waves (Rayleigh [BHZ] and Love [SH]) included in the inversion and their weights\n",
    "6. **tele_waves.json:** Teleseismic body waves (P [BHZ] and SH) included in the inversion and their weights\n",
    "7. **tensor_info.json:** JSON format of the CMT file used as input to the auto inversion. If you want to change hypocenter parameters in future iterations, this is the place to do so.\n",
    "8. **velmodel_data.json:** 1D velocity structure pulled from LITH1.0 and used for the Green's function calculations. You can substitute a different local 1D structure, but you will have to recalculate all the Green's function banks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c999d",
   "metadata": {},
   "source": [
    "##  <a id='input_files'></a>3.1. Managing .json files and updating .txt files:\n",
    "Nearly all necessary inversion parameter modifications should be made within the .json files listed above. Modifications made to the .json files are propagated to the necessary .txt files using the command `wasp manage update-inputs`. Whenever a modification is made to a .json file, run `wasp manage update-inputs` with the appropriate flag to corresponding to the .json file you have modified. The most common are listed below:  \n",
    "1. `-t`: update data types:  \n",
    "    1.0. `-t body`: updates to the teleseismic body wave data (tele_waves.json)  \n",
    "    1.1. `-t surf`: updates to the teleseismic surface wave data (surf_waves.json)  \n",
    "    1.2. `-t strong`: updates to the strong motion accelerometer data (strong_motion_waves.json')  \n",
    "    1.3. `-t cgps`: updates to the high-rate GPS/GNSS data (cgps_waves.json')  \n",
    "    1.4. `-t gps`: updates to the static GPS/GNSS data (static_data.json')  \n",
    "    1.5. `-t insar`: updates to the insar data (insar_data.json')\n",
    "2. `-p`: updates to the fault plane orientation (segments_data.json) or velocity model (velmodel_data.json)\n",
    "3. `-a`: updates to the annealing parameters (annealing_prop.json)\n",
    "4. `-m`: updates to the model space parameters (model_space.json)  \n",
    "\n",
    "'These .json files won't exist until we add those data to the inversion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348c48e",
   "metadata": {},
   "source": [
    "## <a id='modify_jsons'></a>3.2. Remove/ downweight poor stations\n",
    "\n",
    "Next, we will use `wasp manage modify-dicts` to change the weights of stations in the surf_waves.json or tele_waves.json to zero (using the `downweight`) or remove the station entirely (using the `delete` flag). Open the waveform fit plots to decide which stations you want to downweight or remove. \n",
    "\n",
    "Note that station HOPE is super wonky looking in both surface waves (Love and Rayleigh).\n",
    "We will address this by downweighting the station to zero weight using the command `wasp manage modify-dicts`. We could delete the channel completely, but sometimes modifying other parameters allows stations that look wonky in the automated inversion to fit better later. Downweighting to zero allows you to keep seeing the station fit, so you can upweight it again later if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d340c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First run the help command, -h, to see the options\n",
    "!wasp manage modify-dicts --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d06690",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasp manage modify-dicts {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 downweight surf -sc \"HOPE:BHZ,SH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be82247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit these changes by letting the .json files you just modified update their respective text files\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 -t surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fc96ca",
   "metadata": {},
   "source": [
    "Repeat the process above if you want to downweight (or delete) any other body or surface wave observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09566db",
   "metadata": {},
   "source": [
    "## <a id='segments_data'></a> 3.3. Modify the fault orientation parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa09636",
   "metadata": {},
   "source": [
    "By default, the planar fault is divided into ~225 subfaults. But these can end up being weird sizes. Open the segments_data.json file in your favorite editor and modify the delta_dip and delta_strike to be equal integers (i.e., square subfaults). If you make these values smaller, you may to add subfaults in the along-strike and along-dip directions (strike_subfaults and dip_subfaults, respectively) to make sure the fault area isn't too small, and you may want to move the hypocenter subfault location (hyp_stk, hyp_dip), to make sure the slip patch fits on the fault area.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Fault_Orientation.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 1.*** Description of segments_data.json parameters for fault orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ffe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now take a look at the segments_data.json, to modify the fault orientation\n",
    "with open(f'{WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0/segments_data.json', 'r') as sd:\n",
    "    print(sd.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a97157",
   "metadata": {},
   "source": [
    "Open the segments_data.json in your favorite text editor and change some of the parameters. For example: \n",
    "1. make the subfaults 15 x 15 km squares (delta_strike, delta_dip),  \n",
    "2. Change the number of subfaults along-strike or along-dip (strike_subfaults, dip_subfaults),  \n",
    "3. Move the entire fault plane relative to the hypocenter location (hyp_stk, hyp_dip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af862eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that you've updated the fault parameters, you have to confirm this \n",
    "# change by asking the new .json to overwrite its associated text file.\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 -p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648717ae",
   "metadata": {},
   "source": [
    "If you've changed the fault parameterization (and/or the waveforms being used), you also have to recalculate the Green's functions. Luckily, `wasp model run` will do this for you. However, you can also do this manually with the command:  \n",
    "`wasp process greens {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 -t body -t surf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfafdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, re-run the inversion:\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 manual_model -t body -t surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c1259",
   "metadata": {},
   "source": [
    "Let's look at the Love wave fits again. Note that any stations that you deleted are now gone, and any stations you downweighted to zero weight are now shown with dashed lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "display.Image(f'{WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0/plots/Love_surf_waves.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1eb0132",
   "metadata": {},
   "source": [
    "Hey that's looking better! \n",
    "\n",
    "\n",
    "## <a id='shift_match'></a>3.4. Time shift\n",
    "\n",
    "Another simple thing we can do to improve the model is to shift the teleseismic waves in time. The calculated P- and S-wave arrival times might not be perfect (i.e., the velocity model isn't perfect), so we run a simple autocorrelation to align the observations and synthetics better in time. Use the command `wasp process-data shift-match` in either `auto` (default) or `manual` mode. `auto` will use the autocorrelation, while `manual` will allow you to shift it by the number of time steps you prefer. Using the `-p` flag will create a series of plots like Figure 2 to show how the waveforms have been shifted.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/FDF_SH_shiftmatch.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 2.*** Example of result of shift_match.py for SH-wave at station FDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5734f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First up, teleseismic body waves\n",
    "!wasp process shift-match {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 body -o auto\n",
    "# Next up, surface waves\n",
    "!wasp process shift-match {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 surf -o auto\n",
    "# Since you've modified the waveform json files, don't forget to make it official:\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 -t body -t surf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c6230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alright, let's run that inversion one more time and plot the results\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 manual_model -t body -t surf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f71712",
   "metadata": {},
   "source": [
    "### Now you can repeat any of the steps above to modify the fault plane orientation in segments_data.json, remove or down-weight waveforms, shift waveforms in time to align better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d9ed47",
   "metadata": {},
   "source": [
    "## 3.5.  <a id='velmod'></a> Modify crustal velocity model\n",
    "\n",
    "WASP automatically selects a 1D crustal velocity model from the centroid location using LITHO1.0 (https://doi.org/10.1002/2013JB010626). If you have a more specific local velocity model, you can substitute it. It's best to substitute **before** adding local data, to avoid having to recalculate local Green's functions, which can take a while.\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Chile_crustal_velocity_model.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 3.*** 1D crustal velocity model for Northern Chile, from LITHO1.0\n",
    "\n",
    "To modify the local velocity model, open the velmodel_data.json file and input a value for each layer in the velocity model. Run \"wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 -p\" to commit the changes in velmodel_data.json to the corresponding text file, vel_model.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bf4c7",
   "metadata": {},
   "source": [
    "# <a id='add_data'></a>4. And next, we can add local data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deced83",
   "metadata": {},
   "source": [
    "## <a id='strong'></a>4.1. Add  strong motion data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the strong motion accelerometer data (Strong_Motion_Data) to the inversion directory folder:\n",
    "%cp {WASP_tutorial}/StrongMotion_Accelerometer_Data/* {WASP_tutorial}/{event_OT}/{ffm_run}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef6fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder to work in so you don't lose your history:\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.0 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd45a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"manual_model_add_data\" option on \"wasp model run\"\n",
    "# Give it the path to the data directory where you just copied the data (-d ../data/)\n",
    "# Tell it you want it to add the strong motion data (-t strong)\n",
    "# FYI this will take a while, because it also needs to calculate local Green's functions!\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.1 manual_model_add_data \\\n",
    "    -d {WASP_tutorial}/{event_OT}/{ffm_run}/data \\\n",
    "    -t strong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2577039d",
   "metadata": {},
   "source": [
    "Go check out the plots from this run. Note that although plots are automatically made when you run the inversion, you can also manually run plots with additional flags. Let's run the help command to take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25408609",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasp plot neic --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305cd2d2",
   "metadata": {},
   "source": [
    "Let's try re-plotting this solution manually, using the `-l` flag to include the strong-motion station names on the plot, or modify the command below with the flags you'd like from the help command above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bcdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wasp plot neic {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.1 -ffms -t body -t surf -t strong -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1214f",
   "metadata": {},
   "source": [
    "## <a id='cgps'></a> 4.2. Now let's add the high-rate GNSS data, same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d0bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder to work in so you don't lose your history:\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.1 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47647c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the continous GPS data (HR_GNSS_Data) to the inversion directory folder:\n",
    "%cp {WASP_tutorial}/HighRateGNSS_Data/* {WASP_tutorial}/{event_OT}/{ffm_run}/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d364d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"manual_model_add_data\" option on \"wasp model run\"\n",
    "# Give it the path to the data directory where you just copied the data (-d ../data/)\n",
    "# Tell it you want it to add the strong motion data (-t cgps)\n",
    "# FYI this will take a while, because it also needs to calculate local Green's functions!\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.2 manual_model_add_data \\\n",
    "    -d {WASP_tutorial}/{event_OT}/{ffm_run}/data \\\n",
    "    -t cgps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80457bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: If you want to have station ID labels on the map, you can re-run the plot command with the -l flag:\n",
    "!wasp plot neic {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.2 -ffms -t body -t surf -t strong -t cgps -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a70dcf",
   "metadata": {},
   "source": [
    "## Now we have all the kinematic data included, let's move onto the static data\n",
    "### <a id='gps'></a> 4.3. Starting with the static GNSS/GPS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a7634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.2 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the gps_data text file into your working directory:\n",
    "!cp {WASP_tutorial}/Static_Data/gps_data {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da618d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gps_data file to create the necessary .json file:\n",
    "!wasp manage fill-dicts {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 -t gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'wasp manage update-inputs' to make the update to the json official:\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 -t gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d57e7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to make Green's functions for the static station locations:\n",
    "!wasp process greens {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 -t gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb8bec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Alright, run a new inversion (and make plots) with all the available data so far!\n",
    "# Keep in mind that every time you add new data, the inversion will take a bit longer...\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 manual_model -t body -t surf -t strong -t cgps -t gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38798812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: to add station ID to all the local stations, replot with the -l flag:\n",
    "!wasp plot neic {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 -ffms -t body -t surf -t strong -t cgps -t gps -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1abd6d",
   "metadata": {},
   "source": [
    "## Looking good! <a id='insar'></a> 4.4. Time for InSAR data:\n",
    "### Prior to inclusion in WASP, InSAR observations must be processed to line-of-sight displacements, and down-sampled to some tractable number of observations (~1000 points per scene). Use the format in the example data files. Denote any header lines with '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e372673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.3 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d251057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the downsampled InSAR data into the working directory\n",
    "!cp {WASP_tutorial}/Static_Data/s1_20150824-20150917_p156_descending.txt {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4/\n",
    "!cp {WASP_tutorial}/Static_Data/s1_20150826-20150919_p18_ascending.txt {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the necessary InSAR json files:\n",
    "# For organization (it doesn't matter for the inversion), mark the ascending file as -ina\n",
    "# Mark the descending file as -ind\n",
    "# WASP can allow for linear, bilinear, and quadratic \"ramps\" for each scene\n",
    "# Ramps are are specified by \":<ramp type>\" to the file path.\n",
    "# Here, we'll use the simplest version, linear ramps, for both.\n",
    "!wasp manage fill-dicts {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4 \\\n",
    "    -t insar \\\n",
    "    -ina {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4/s1_20150826-20150919_p18_ascending.txt:linear \\\n",
    "    -ind {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4/s1_20150824-20150917_p156_descending.txt:linear;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348647e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 'wasp manage update-inputs' to make the update to the json official:\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4 -t insar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcluate Green's functions.\n",
    "# With a lot of data points, this could take a few minutes\n",
    "!wasp process greens {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4 -t insar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ad134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run the inversion with all the data!\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4 manual_model -t body -t surf -t strong -t cgps -t gps -t insar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259d94d",
   "metadata": {},
   "source": [
    "### And there you have it, a finite fault model that includes many different instrument types.\n",
    "Go check out your plots! To finalize the inversion, go back and modify the fault orientation, subfault size, shift waveforms in time to match synthetics to observations better, remove bad stations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22657490",
   "metadata": {},
   "source": [
    "# <a id='multi_segment'></a> 5. Multi-segment models\n",
    "At present, WASP requires that slip be solved for on planar faults. However, we are not limited to one fault segment. WASP can model on 2+ planar segments, either connected at fault edges or completely independent. The 2015 Illapel earthquake ruptured only one fault (the megathrust), however, we can do a better job mimicking the increasing dip of the subduction zone with depth by changing our model from one plane with constant dip to two planes, with the deeper plane having slightly steeper dip.\n",
    "\n",
    "To include more than one planar fault segment, you must adjust two files:  \n",
    "1. segments_data.json  \n",
    "* Use hyp_stk and hyp_dip to locate the fault, relative to the location of the hypocenter\n",
    "* Use the “connections” field to describe how multiple planes are connected, in order to facilitate smoothing across the faults.\n",
    "2. model_space.json\n",
    "* Specify any constraints on slip amplitudes and allowable rakes\n",
    "* Specify whether plane is connected to any other planes in the up- or down-dip directions, or to the left or right (i.e., in the negative or positive along-strike directions)\n",
    "\n",
    "Examples of how you might modify these two files are in the Multisegment_Example folder.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"Tutorial_Figures/Multi_Segment_Positions.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "***Figure 4.*** Example of determining \"hyp_stk\" and \"hyp_dip\" for multi-segment models connected along-strike (segment 2) or along-dip (segment (3).\n",
    "\n",
    "In our case, the bottom of the shallow plane is connected to the top of the deeper plane. However, segments need not be connected at all- this is how you might model two events in close spatiotemporal proximity at once (e.g., Yeck et al., 2023). \n",
    "\n",
    "* Yeck, W.L. et al. Dense geophysical observations reveal a triggered, concurrent multi-fault rupture at the Mendocino Triple Junction. Commun Earth Environ 4, 94 (2023). https://doi.org/10.1038/s43247-023-00752-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50128cbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a new folder so you don't lose your history:\n",
    "!cp -r {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.4 {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77275b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the example segments_data.json and model_space.json from the Multisegment_Example directory:\n",
    "!cp {WASP_tutorial}/Multisegment_Example/segments_data.json {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.5/\n",
    "!cp {WASP_tutorial}/Multisegment_Example/model_space.json {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.5/\n",
    "# Run 'wasp manage update-inputs' to update the text files associated with those json files:\n",
    "!wasp manage update-inputs {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.5 -p -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80eb1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command will now update the Green's funcitons for the new configuation, run the inversion, and plot the results:\n",
    "!wasp model run {WASP_tutorial}/{event_OT}/{ffm_run}/NP1.5 manual_model -t body -t surf -t strong -t cgps -t gps -t insar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834c2cbd",
   "metadata": {},
   "source": [
    "In these results, you will see some subtle changes. First, you now have 2 SlipDist plots, one for each plane. Also, when you open the Map plot, you'll see the two segments are separated, and there are now two red up-dip edges, one for each plane. This is fairly simplistic version of a multi-segment model, but users are encouraged to make their own more complex multi-segment models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32361097",
   "metadata": {},
   "source": [
    "### Congrats! You are ready to explore WASP on your own and model earthquakes of interest to you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
